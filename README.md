# AI Research Papers Reading List

## Theoretical & Understanding
* [Neural Networks are Decision Trees](https://arxiv.org/abs/2210.05189 "Neural Networks are Decision Trees: Generalizing Tree Decompositions to Graphs (Rymenams et al., 2022)")
* [Cross-Validation Bias due to Unsupervised Preprocessing](https://arxiv.org/abs/2104.12834 "Cross-Validation Bias due to Unsupervised Preprocessing (Bijma et al., 2021)")
* [The Forward-Forward Algorithm](https://www.cs.toronto.edu/~hinton/FFA13.pdf "The Forward-Forward Algorithm: Some Preliminary Investigations (Hinton, 2022)")
* [LoRA](https://arxiv.org/abs/2106.09685 "LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)")
* [Grokking](https://arxiv.org/abs/2201.02177 "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets (Power et al., 2022)")
* [Deep Learning Through the Lens of Example Difficulty](https://arxiv.org/abs/2106.09647 "Deep Learning Through the Lens of Example Difficulty (Swayamdipta et al., 2021)")
* [The Mechanical Turk](https://arxiv.org/abs/2301.13314 "The Mechanical Turk: How Transformers Process Mathematical Structure (Malkin et al., 2023)")
* [Transformer Feed-Forward Layers Are Key-Value Memories](https://arxiv.org/abs/2012.14913 "Transformer Feed-Forward Layers Are Key-Value Memories (Geva et al., 2020)")
* [Language Models (Mostly) Know What They Know](https://arxiv.org/abs/2305.13711 "Language Models (Mostly) Know What They Know (Kadavath et al., 2023)")
* [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361 "Scaling Laws for Neural Language Models (Kaplan et al., 2020)")

## Foundation Models & Architecture
* [PaLM](https://arxiv.org/abs/2204.02311 "PaLM: Scaling Language Modeling with Pathways (Chowdhery et al., 2022)")
* [PaLM 2 Technical Report](https://arxiv.org/abs/2305.10403 "PaLM 2 Technical Report (Anil et al., 2023)")
* [Constitutional AI](https://arxiv.org/abs/2212.08073 "Constitutional AI: A Framework for Machine Learning Systems that Respect Human Values (Askell et al., 2022)")
* [UL2](https://arxiv.org/abs/2205.05131 "UL2: Unifying Language Learning Paradigms (Tay et al., 2022)")
* [PaLI](https://arxiv.org/abs/2209.06794 "PaLI: A Jointly-Scaled Multilingual Language-Image Model (Chen et al., 2022)")
* [Mixture of Experts Meets Instruction Tuning](https://arxiv.org/abs/2305.14705 "Mixture of Experts Meets Instruction Tuning (Zhou et al., 2023)")
* [Mamba](https://arxiv.org/abs/2312.00752 "Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Gu & Dao, 2023)")
* [Mistral 7B](https://arxiv.org/abs/2310.06825 "Mistral 7B: A New Era in Open LLM (Jiang et al., 2023)")
* [Phi-2](https://arxiv.org/abs/2310.16782 "Phi-2: The surprising power of small language models (Li et al., 2023)")
* [RWKV](https://arxiv.org/abs/2305.13048 "RWKV: Reinventing RNNs for the Transformer Era (Peng et al., 2023)")

## Training Techniques & Optimization
* [QLoRA](https://arxiv.org/abs/2305.14314 "QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al., 2023)")
* [LongNet](https://arxiv.org/abs/2307.02486 "LongNet: Scaling Transformers to 1,000,000,000 Tokens (Ding et al., 2023)")
* [Sparse Mixers](https://arxiv.org/abs/2310.19906 "Sparse Mixers: Combining MoE and State Space Models for Memory-Efficient LLMs (Yu et al., 2023)")

## Vision & Multi-Modal

### Vision Transformer Series
* [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929 "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (Dosovitskiy et al., 2020)")
* [Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294 "Emerging Properties in Self-Supervised Vision Transformers (Caron et al., 2021)")
* [Data-Efficient Image Transformers](https://arxiv.org/abs/2012.12877 "Training data-efficient image transformers & distillation through attention (Touvron et al., 2021)")
* [Swin Transformer](https://arxiv.org/abs/2103.14030 "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (Liu et al., 2021)")
* [ConvNet for 2020s](https://arxiv.org/abs/2201.03545 "A ConvNet for the 2020s (Liu et al., 2022)")

### Diffusion Models
* [Latent Diffusion Models](https://arxiv.org/abs/2112.10752 "High-Resolution Image Synthesis with Latent Diffusion Models (Rombach et al., 2022)")
* [DDPM](https://arxiv.org/abs/2006.11239 "Denoising Diffusion Probabilistic Models (Ho et al., 2020)")
* [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598 "Classifier-Free Diffusion Guidance (Ho & Salimans, 2022)")

### Multi-Modal Advances
* [CLIP](https://arxiv.org/abs/2103.00020 "Learning Transferable Visual Models From Natural Language Supervision (Radford et al., 2021)")
* [VQGAN](https://arxiv.org/abs/2012.09841 "Taming Transformers for High-Resolution Image Synthesis (Esser et al., 2021)")
* [Segment Anything](https://arxiv.org/abs/2304.02643 "Segment Anything (Kirillov et al., 2023)")
* [DINOv2](https://arxiv.org/abs/2304.07193 "DINOv2: Learning Robust Visual Features without Supervision (Oquab et al., 2023)")
* [PaLI-X](https://arxiv.org/abs/2305.18565 "PaLI-X: On Scaling Up a Multilingual Visual Language Model (Xi et al., 2023)")
* [Flamingo](https://arxiv.org/abs/2204.14198 "Flamingo: a Visual Language Model for Few-Shot Learning (Alayrac et al., 2022)")
* [ImageBind](https://arxiv.org/abs/2305.05665 "ImageBind: One Embedding Space To Bind Them All (Goh et al., 2023)")
* [Muse](https://arxiv.org/abs/2301.00704 "Muse: Text-To-Image Generation via Masked Generative Transformers (Chang et al., 2023)")
* [GPT-4V](https://cdn.openai.com/papers/GPTV_System_Card.pdf "GPT-4V(ision): An Overview of Multimodal Capabilities (OpenAI, 2023)")
* [CM3leon](https://arxiv.org/abs/2308.08947 "CM3leon: A General-Purpose Multimodal Model (Lu et al., 2023)")
* [LLaVA](https://arxiv.org/abs/2304.08485 "Visual Instruction Tuning (Liu et al., 2023)")

## NLP & Language Models
* [GPT-3](https://arxiv.org/abs/2005.14165 "Language Models are Few-Shot Learners (Brown et al., 2020)")
* [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903 "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., 2022)")
* [InstructGPT](https://arxiv.org/abs/2203.02155 "Training language models to follow instructions with human feedback (Ouyang et al., 2022)")
* [Chinchilla](https://arxiv.org/abs/2203.15556 "Training Compute-Optimal Large Language Models (Hoffmann et al., 2022)")
* [Flan](https://arxiv.org/abs/2301.13688 "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning (Chung et al., 2023)")
* [LLaMA](https://arxiv.org/abs/2302.13971 "LLaMA: Open and Efficient Foundation Language Models (Touvron et al., 2023)")
* [LLaMA 2](https://arxiv.org/abs/2307.09288 "Llama 2: Open Foundation and Fine-Tuned Chat Models (Touvron et al., 2023)")
* [Toolformer](https://arxiv.org/abs/2302.04761 "Toolformer: Language Models Can Teach Themselves to Use Tools (Schick et al., 2023)")

## Retrieval & Memory
* [RETRO](https://arxiv.org/abs/2112.04426 "Improving Language Models by Retrieving from Trillions of Tokens (Borgeaud et al., 2021)")
* [Atlas](https://arxiv.org/abs/2208.03299 "Atlas: Few-shot Learning via Memory Access with Large Language Models (Yu et al., 2022)")
* [Memorizing Transformers](https://arxiv.org/abs/2203.08913 "Memorizing Transformers (Wu et al., 2022)")
* [Self-RAG](https://arxiv.org/abs/2310.11511 "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection (Asai et al., 2023)")
* [Internet-Augmented Generation](https://arxiv.org/abs/2302.04245 "Internet-augmented dialogue generation (Liu et al., 2023)")
* [Multimodel RAG](https://arxiv.org/abs/2401.00812 "MultiModal RAG: Learning to Retrieve, Generate, and Ground across Modalities (Yasunaga & Rong, 2024)")
* [RAPTOR](https://arxiv.org/abs/2401.18059 "RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval (Kandpal et al., 2024)")

## Agents & Planning
* [ReAct](https://arxiv.org/abs/2210.03629 "ReAct: Synergizing Reasoning and Acting in Language Models (Yao et al., 2022)")
* [Tree of Thoughts](https://arxiv.org/abs/2305.10601 "Tree of Thoughts: Deliberate Problem Solving with Large Language Models (Yao et al., 2023)")
* [Graph of Thoughts](https://arxiv.org/abs/2308.09687 "Graph of Thoughts: Solving Elaborate Problems with Large Language Models (Chen et al., 2023)")
* [LLM+P](https://arxiv.org/abs/2304.11477 "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency (Liu et al., 2023)")
* [Tool-Learning](https://arxiv.org/abs/2311.10775 "Tool-Learning with Foundation Models: A Survey (Zhou et al., 2023)")
* [Reflexion](https://arxiv.org/abs/2303.11366 "Reflexion: Language Agents with Verbal Reinforcement Learning (Shinn et al., 2023)")
* [AutoGen](https://arxiv.org/abs/2308.08155 "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation (Wu et al., 2023)")

## Systems & Efficiency
* [FlashAttention](https://arxiv.org/abs/2205.14135 "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness (Dao et al., 2022)")
* [FlashAttention-2](https://arxiv.org/abs/2307.08691 "FlashAttention-2: Faster Attention with Better Parallelism (Dao et al., 2023)")
* [MEGABYTE](https://arxiv.org/abs/2305.07185 "MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers (Anil et al., 2023)")
* [vLLM](https://arxiv.org/abs/2309.06180 "vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention (Kwon et al., 2023)")
* [TokenFlow](https://arxiv.org/abs/2401.00448 "TokenFlow: Consistent Diffusion Features for Consistent Video Editing (Hesse et al., 2024)")
* [Gorilla](https://arxiv.org/abs/2305.15334 "Gorilla: Large Language Model Connected with Massive APIs (Patil et al., 2023)")

## Evaluation & Safety
* [Scalable Oversight](https://arxiv.org/abs/2211.03540 "Measuring Progress on Scalable Oversight for Large Language Models (Askell et al., 2022)")
* [Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916 "Language Models are Zero-Shot Reasoners (Kojima et al., 2022)")
* [Watermarking](https://arxiv.org/abs/2301.10226 "On the Reliability of Watermarks for Large Language Models (Kirchenbauer et al., 2023)")
* [Pythia](https://arxiv.org/abs/2304.01373 "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling (Biderman et al., 2023)")
* [ToxiGen](https://arxiv.org/abs/2203.09509 "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection (Hartvigsen et al., 2022)")
* [Red Teaming Language Models](https://arxiv.org/abs/2202.03286 "Red Teaming Language Models with Language Models (Perez et al., 2022)")
* [DecodingTrust](https://arxiv.org/abs/2306.11698 "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models (AlQaraawi et al., 2023)")

## Novel Applications
* [NeRF](https://arxiv.org/abs/2003.08934 "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (Mildenhall et al., 2020)")
* [AlphaFold](https://www.nature.com/articles/s41586-021-03819-2 "Highly accurate protein structure prediction with AlphaFold (Jumper et al., 2021)")
* [Bayesian Flow Networks](https://arxiv.org/abs/2308.07037 "Bayesian Flow Networks")